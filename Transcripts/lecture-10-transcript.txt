First thing we're going to do is wrap up this... Look at this state chart of an automatic braking system. The point in this is that all the controls... All the actions are done after the changes of state. So it shows you as you're moving from state to state. The advantage of putting an action after an event in terms of moving into a change of state is that if you're entering the same state from different locations, obviously you can have different actions. It's a bit more flexible. So by putting it on the arc, you can make it relevant to why you're moving into that particular state. So for example, if you're moving back to an idle state, you might want to reset various conditions as you move back into that idle state. It wouldn't necessarily be the same thing, would it? So you might be resetting an error or switching something off, etc. So if you think of it in that context. Anyway, we will be moving on from this because we want to move on to state charts. So here we are to finite state machines. So finite state machines, also known as automata, are similar to the state charts. So they have state, but they have some extra notation. So finite state machines are very often used to do things like modelling, things where you recognise a pattern of incoming data. So an example I can give you that is spell checking when you're on a word processor. When you're spell checking on a word processor, as you type across, it's determining whether the word you've typed is correct or not. It's doing it in a context-aware manner. So for example, if I type the word C, that's okay because even though C is not a word, it's a letter that can prefix other words. So I'm still in a state where I'm still recognising. If I put the letter A and I'd still be in a state where I was recognising, so I'd have an incoming A, and then I'd have T, and that's okay because it can be cut together. But if I then had the letter Z, in English, there's no word that starts in C A T Z, I would be in a state where I'd be not recognising. So I'm doing it in terms of context, because if I come in with the letter Z, because there's plenty of words that start with the letter Z, evidently it's still in a recognising state. So the thing is about a finite state machine, it's context-relevant, it's useful for doing these things where you're doing something computationally but it's relevant to a context. So if you think of anything like spell checking, grammar analysis, understanding words, parsing something, a state machine is a good way to handle that process. It's a good way to do something where you're recognising a pattern, and it's context-relevant. So where you put your keywords in your programme, sometimes it says there's a syntax error, sometimes it says it doesn't, even for the same keyword. So the order of things is relevant. If you do an expression like 7 minus 6, that means something different than 6 minus 7. And evidently, a state machine will understand that in terms of fitting operators or operands in what it expects to get next. So you might have, if you were parsing this, you might have a state machine that was at first looking for an operand, then when it's found an operand, then it's looking for an operator moving between the two states. So the thing about finite state machines is they're very often used to solve those kind of problems. Another example is predictive text. So you used to have that predictive text thing where you're typing and it tries to work out what you might be doing next. Obviously, the number of predictive words is dependent on the internal state of the predictive text finite state automata. So it's used in that context. It's very useful for modelling thinking. So in general, finite state machines have a series of states, obviously. So it's very similar, but it has this idea of an initial state, so we've seen that before, but an input alphabet and this idea of a transition function. So the transition function is saying where we're going from one to the next one. So if you look at this one, notice this is the recognised state and it's looking for a series of patterns. So it starts off here in state one and if it sees AAB, that's a recognised pattern, AB is a recognised pattern, and BBB. So in this context, anything that's ending in a B has got to a recognised state, regardless of any sequence that starts off with AAB or AB and then any combination of A and B. Notice, once I've got that prefix, it stays in that recognised state. It doesn't really care if I have A or B. It's a very abstract example. It's not really useful. Maybe it's useful to think of the spell checker. That's actually a practical example of how a finite state machine would work. When you do the spell checker, you could have your finite state machine be built dynamically. What you would do is start off with an empty finite state machine and every time you put in a valid word, it would construct a pattern across the finite state machine. A little bit like a tree. It would use a tree to determine. Typically for English, you'd have a start state and then you'd have 26 ways that you could get out of that start state because there's 26 letters in the English alphabet. So you can think of a way you could model that yourself. You could have a go at it, try it as a small program. So the computation starts at the start state. Every time you have an input thing, it moves to the next state. And the state transitions move it from one state to another and you have the rules and conditions. We're going to move to the next lecture slide because obviously we're moving on to lecture 8 as we move through. So we're going to actually look at a couple of different finite state machines. So this is carrying on, talking about system models. So we're going to look at what are Mealy machines and Moore machines. Then we're going to look at another type of way of analysing state called Petri nets. Petri nets are interesting in the fact that they have properties such as they can have an infinite number of states. So they're a lot more powerful than finite state machines and they have the ability to move to another state that is not predictable in the same as finite state machines. We're going to look at them in more detail in the end of this lecture and then moving into the next lecture. The important thing about all these is they provide a more formal approach to describe the behaviour, the internal behaviour of the system. So as it's formalised, evidently, then you can make predictions about it and it doesn't have the same ambiguity as describing it just in English. So we've got our finite state machine, it moves from state to state, it depends on this incoming and this one has a recogniser. This is a recogniser thing for this finite state. So it's useful for looking for patterns. Another use for finite state machines is looking for prefixes on communication protocols. So fixed patterns of 1s and 0s. So for example, Ethernet uses a fixed pattern of 1s and 0s coming into the bank. And as that's fixed, it's very unlikely to happen just randomly, like a random set of errors of 1s and 0s, because it's quite a long sequence. You know, let's say 32, 64 bits, so it's one way of doing that. So it can be used for that as well. So you start off in the start state, here we go into state 1, depending if you get A or B you go to 2 or 4, when we're in 2, depending if I got A or B I go to 3 or 5. Notice, because the alphabet here is only two letters long, it's only going to have two choices coming out of each one. State transitions moving from one state to another. The input events for these, in this sense, are using an input alphabet, but it's also possible to do it based on a timeout, okay, an internal triggered rule. There are two variants of finite state machines we're going to look at. One is more powerful than the other, and hence one can actually encompass the full subset of the other. So these are called the Mealy machine and the Moore machine. In general, these can have more than one start state, so you can start in different places, and it's possible to actually just transition based on not being a symbol, or you can have multiple symbols. So you can have what's called a non-deterministic finite state machine. When you do Petri nets, they have a feature of allowing to be non-deterministic, so a Petri net, that has something called non-determinism. Non-determinism means we don't know what's going to happen next. It's random, there's a sense of randomness. And actually in a lot of computer systems, you don't know exactly what's going to happen next. You can click the mouse at any time, timing is random, you have information coming down an information network, you don't know when the next network packet's going to arrive, etc. And you can have one or more states designated as the accepting state. So if I think of my language recognizer for my spell checker, that would have as many accepting states as there are words in the English language, if it was for English. Okay, so if there's 32,000 words in the English language, it would have 32,000 accepting states, evidently. Mealy machines and Moore machines map an input to an output. So essentially, what they're doing is they're doing some computation and then changing the input to an output device. So, so far when we've looked at the finite state machine, we've just seen if it gets into this state which has the two circles. Okay, so for our spell checker, it's whether the thing is spelt or not. We can also make a finite state machine process an input and produce a stream of output. Okay, so a simple example would be just something that did a two's complement of an incoming number. So it got a one, translated to a zero. In fact, if you think of things like a shift register in hardware, a shift register is a finite state machine. It's a number of finite states, you can clock it and move bits in and out of it, it has some internal state and it has an output. The Moore machine is a finite state automator, but it has two extra attributes. It has an input and an output alphabet now. And that allows us to process an input stream of characters and get an output stream of characters coming from it. For the states themselves, they have an output letter associated with that state. So when you enter that state, you get that output letter. So for example, if I have a state like that and I have the letter Z, when I go into this state, the letter Z is output from the finite state automator. Only once, it doesn't just keep doing it, but every time you re-enter the state. So here's an example of a Moore machine. So we start off in state Q0, as soon as we enter, it outputs the digit 1, then if we get A coming in, we get the digit 0, and if we get B, we get digit 1. And we just keep going round here like this. So in this example, I start off here, I have 1 immediately on the output, then I have the letter A, notice now 0 comes on the output, and then I have A, the next one is a B, so it goes back to here, so another 0, I'm still in this state, then an A, it moves to here, I get a 1 on the output, and then another B, B moves me to here and it gives me a 0 on the output. So what it's doing is it's mapping a series of incoming signals to the output. So the important thing here is to note that the output is dependent on the incoming sequence and the current state. So obviously that's a context-dependent transformation. So here we've got another example of a Moore machine. This is looking for patterns. So if you look at this, it's looking for a pattern of A, A and B, and then it outputs a 1. As soon as it gets an output to 1, it can then flip back again depending on the pattern. So if you get another A, and then A, A, B, it outputs another 1. Notice it's looking for A, A, B, because see here where it's got one A, A, B, if it gets another sequence A, A, B, it flips back to here again. If it gets a B, that's a delimiter, and then it's looking for the initial pattern. If it doesn't get this pattern, it keeps flipping back to Q0. So every time it doesn't get the pattern, it goes back to Q0 looking for that pattern again. So it's counting every time it sees A, A, B. So it sees A, A, B, puts a 1 on the output. It sees A, A, B here, puts 1 on the output. So you can see it as a counter. Obviously, it's just converting this to streams, but this count isn't really in binary or something, it's just generating a little 1 every time it sees that incoming pattern. And you can make it more complex, and you could use this for something which was determining, as I said, in a data communication protocol, if you were looking for a fixed pattern before you said you've got the start of the frame, you could look that for a signal to clock something. This typically will be done in hardware, not in software, but you can use it to model things in software. Remember, everything that can be done in hardware can be done in software, because software can do anything. The hardware can do certain basic things like shift stuff about, move registers, etc. The software can do absolutely anything you can imagine. So it's very, very flexible. So you can implement this. Obviously, if you were doing it as fast as you could, you could just do it in hardware. You could do it with shift registers, you could do it with OR gates, AND gates, bits and pieces of logic. So this one does a 1 every time it sees AAB. So the Mealy machine, it says computationally equivalent to a Moore machine. That means that you can do all of 1, any Mealy machine, you can do using a Moore machine. The difference is that when you do it with a Moore machine, you might need more states to do it in. As we'll see from the Mealy machine, it's a little bit more powerful, it's a bit more adaptive. So with a Mealy machine, the output, instead of being in the actual state itself, is in the transition from one state to another. Which makes them very flexible, because I can move into a state and have different outputs depending on where I came from. So it's where I come from and where I go to that says what symbol I get on the output. So look at this example here. If you look at this, we are starting off here, and we have an input character. Notice in this, remember with the previous one, we got one more symbol on the output than we had symbols on the input, because as soon as we entered it, we got a symbol going out. But in this it's exactly the same number. So I get an A, it gives me a zero, I go to this state, so that's zero. Then I do another A, I get a one coming out, and then I get another A, I get a one coming out. These examples are obviously more powerful Mealy machines, because they are more adaptable, because entering state 3 I can go one or zero, of the flexibility of that. But the other thing to note about the Mealy machine is that it may need less state to actually represent it. So in practice it's a more practical thing for doing more complex systems. So the Mealy machine, every time you go from one transition to another, the transitions are labeled I/O, where the I is the one that sends it, and the output is what comes out. So if you look at this very simple Mealy machine, that's changing a number. What's that doing? What operation is that called? Have you done that computational correction? I don't know what that's called. Where you flip the bits, it's got a name. What was it called there? It's called a complement. It's called a one's complement. One's complement is a way of representing negative numbers. So if I wrote this, if I write four bits, that's plus one, and then in one's complement, that's minus one. Isn't it weird because there's two representations for zero? All one's in zero, and all zero's in zero. When you add them together, and you get all one's, what you do is get zero. That's why we use two's complement. We add one on afterwards, and it means you only get one representation. In practice, you will have learned two's complement, one's complement, it is what it is. It has this double representation of zero, so it's not written very handy. That's why we use two's complement in practice. It's also used when you have a not symbol. If you've got Java and you go if not something, it's essentially complementing the Boolean value. It's changing true to false and false to true. The thing to note about the Mealy machine, every time you have an input character, or a transition on each character, you get an input alphabet on every single state. You don't need an except state because it just produces an output. The output itself could be seen as a series of acceptances or counts or whatever, but it doesn't have this end state where you say that one state is more important than the others. The thing to note about it is that all the states appear, there's no like this special state. That's the thing to note about it. The next two lectures are going to be going into detail about Petronet. Petronet is very powerful and they are developed by somebody who was extremely smart. Another Petronet, Karl-Adam Petri, when he was 12 years old, which is insane really because he was incredibly young and it's a really cool thing, and he did a dissertation, they had originally done some model chemical reactions. What's interesting about chemical reactions is you can have the oxygen there, the two hydrogens there to make H2O to make water, they can sit there and sit there and sit there and then suddenly they can react. Petronets have this idea that suddenly something happens without there having to be anything to make them happen. They can sit in a state where they can move from one state to another, but that jump is non-deterministic. When things happen in Petronets can be non-deterministic, you don't know when they're going to happen, and also which change of state can also be non-deterministic, you don't know where it's going to go. When you look at the state machine, we know we've got this input, it jumps this output, it's more like a clock, it goes from one to the other to the other, Petronets are set up where some things can happen and more than one thing can happen, and any of those things can happen, you don't know which that's important. So there's been a lot of research done into Petronets, there's people who've written the whole research papers on them. So there are some mathematical properties including reachability and etc, but we're going to just learn the basics, the foundations, then we're going to look at a practical use of modelling with Petronets. So let's have a look at a Petronet in practice. A Petronet consists of a number of places, this circle here, in fact if you look very carefully you'll see it's in dark blue, but it can be in black or blue, and it's just been done in blue just to highlight it. In general for the exam they're all going to be in black and white anyway so it won't make any difference, but it's a circle. This thing inside it, this little thing is called a token. Okay so tokens sit in places, they're in places. Connecting the places from one place to another are arcs and transitions, so that arc here has something called a capacity of one. If it has a capacity different than one, you have a little number next to the arc telling you what the capacity is. This is a transition, and there's another place, but this place currently doesn't have a token. So places hold tokens, and the state of the marking of the Petronet is the assignment of tokens. In this example, the placing of this one you'd do right as a tuple and it's just 1,0 like that. Because you've got one token in place 1 and zero tokens in place 2. The arcs themselves have something called a capacity, but that doesn't mean they actually store anything, it's to do with what happens if the transition fires. The places by default can have as many tokens as you like, infinite. I mean obviously it will have, that really could say indefinite, you could have as many tokens as you like. The transitions don't have any capacity, cannot store tokens. In fact the tokens themselves are only stored within the places. Arcs connect places to transitions, and then they also connect the transitions to another place. So we're going to add some other features, we're going to look at timing and colour in future lectures. So let's have a look at some examples. This one on the left, transition 1. Notice for this to be enabled, transition 1, it has to have a token on every place coming in. In fact the number of tokens has to be equal to the capacity of the arc. Notice in this one, this is just 1. So this is enabled, because there's a token here and a token there. If it fires, what happens is, for every incoming arc, the token is consumed, is taken, and then new tokens are generated on the output. Tokens are not moved from the input to the output. Tokens are not something that move around Petronets. They disappear from the inputs when you fire, they're regenerated on the output. So notice, they're not conserved. So I have 3 tokens here, I have 3 down here, I could have a Petronet where I start off with 4 tokens and end up with 2 after firing. So the number of tokens total across the Petronet can go up or down. They're not a conserved thing. You can have arcs that have multiple weights. Look at this one, where I've got here, I've got a weighting of 2 on the left hand and I've just got a weighting of 1. That again is enabled because I have 2 tokens. If I had only 1 token on the left, this would not be enabled. Then it can fire. Notice, you don't know when it's going to fire. It could fire now, you could have to wait 100 years, it could never fire. There's no clock in this, there's no timing. Then when it fires, stuff is produced on the output depending on the weighting of the output. So notice this fires because this has a weighting of 3. 3 tokens are generated here, 2 tokens are generated there, 1 token is generated there. When it moves along, notice the state marking of the Petronet will change from state to state to state to state as you move along. It's also possible to have a notation which allows the Petronet to be inhibited by the presence of a token. In this case, the Petronet cannot fire because P1 is on here. This little circle reverses the logic of the arc relationship with the thing. So here are some examples of different computational structures in terms of what can happen by using Petronets. So Petronets can be used to model events that can happen either in the real world or within the computer itself. So this first one locks T1 and T2. Notice T1 is going to only happen first. T2 cannot fire until T1 is fired because T2 is waiting for an output in P2 and that output in T2 will only happen when T1 is fired. So we have a sense of order here, sequence. Here we have either this or this or this can fire. Imagine a situation where you want to allocate, you have a system where you have a number of servers running and you want to allocate a request to one of those servers but you are not sure which one it is going to go to. Notice it is one of these that the situation is going to be allocated to. This is quite distinct. This is concurrent because after T6 fires all of these states are going to be enabled. So this implies that we have finished a process of T6 and now some process of T7, T8 or T9 can happen at the same time. There must be something happening here. Remember we looked at, we did modelling for process modelling and we imagined a situation where three things can happen at the same time in our model. The PetriNet is good for designing them. Then we have got one called synchronization. In this, notice I have to have P8, P9 and P10 enabled to allow the PetriNet to actually fire at T10 here. So this is a good example of synchronization because all of these have to be true. Then this one is somewhat confused because T12 is enabled if these two are enabled but as soon as T11 or T13 fire then this will be disabled. Then we have got what is called merging. What this is waiting for is it is waiting for an event to happen from any one of these before it can proceed onto T17. And then finally we have got what is called priority inhibit. This is inhibiting, so any presence here is inhibiting the flow of the fire here. And this one is saying that this one is allowing either this to flow or this to flow but this one is switching that off. Remember the PetriNets themselves were developed for chemistry. I have just got a quick example here just to show you how it applies to chemistry. If I was producing one molecule of water I would need two atoms of hydrogen and one of oxygen. If I set this PetriNet up what does this transition here represent then? What does that represent? If that fires what has happened? It is called a chemical reaction. So you can see how useful they are because you don't know. If you can put hydrogen and oxygen together they are not going to react immediately. You can see you get one molecule of water out of the end so it has got the idea of constructing out of three things one thing. So you have got an essence. You can see how PetriNets are not just about getting the timing or the synchronization but they are representing something in the real world. And when we use PetriNets there is a lot of thing where we are using this mapping of the model which looks rather abstract with its dots to real things, real things that are happening. So they are useful for anything that is non-deterministic. Distributed systems like computers that sit there at servers are non-deterministic. If I have a server that sits and is waiting for an incoming request to do some shopping or something like that it has no idea when those incoming requests are going to be. It doesn't know what the incoming requests are and it has requests from lots of different sources and the timing characteristics. It also has complex internal state. Obviously anything where it is non-deterministic and has complex internal state it maps to PetriNets. So we don't know which one is going to happen. So inside this server I might have three accounts that are logged in. One that has got something happening and you have got some items in the shopping cart. You can think of items in the shopping cart. Tokens that people have added to it as the incoming stimuli come in. So that ability to buy the thing, I can't buy anything until I have got something in the shopping cart. So you can imagine you can build up a schema of these to describe the internal flow of the processes inside. So we are going to look at some variations and extensions of these as well. The other thing to note about the PetriNets is they have a proper mathematical notation. So we are going to look at that again in the next lecture. The other thing is worth just noting at this point, we are going to look at it in more detail in later lectures, is semantic data models. So they show you the structure of data. When you do class diagrams, class diagrams are semantic data models, effectively types of them. And also entity relationship diagrams and entity relationship models. So they are used in database design and you should be looking at those probably in comp 207. We do something similar, we do class diagrams, but class diagrams are a bit more expressive. They allow you to put a bit more in. So there is nothing within notation, within UML to do these, but there is class diagrams which are somewhat similar in use. So there is an example of a one for a software design. Notice this is a semantic data model which refers to itself. So these are all nodes, they have links in between them and they have names, look there is names on the nodes and they have types. Each node, each link has two nodes. So if I look at this link here, it has a node here and a node there. Each node has multiple end links, so if I look at this node here it has one, two, three links. This node has one, two, three, four links. So this is a sort of self referential semantic model. The other thing that you might want to model are data dictionary entries, not used so much commonly nowadays, I'll get round those. But they are useful if you want to deal with handling your names and variable management. So there is an example of a data dictionary for that semantic thing. So it is showing you that has labels is a relationship, so there is something about it. And then this link is something called a relationship which shows the linkage between two other things. And then the name, they are just strings, they are just attributes. There are object models, so we are going to look at those in more detail later. They are going to show you how those work, but we are going to be doing those in more detail later. So I am not going to talk a lot about them now because we are going to cover that in a lot more detail. But they will be able to map the real world into our software system. Part of coursework too is to do UML and UML is useful because if you are working in a lot of organizations, they may well be using UML to do your object oriented analysis. So we are going to be doing this again in more detail later. So use case diagrams as part of UML, class diagrams, sequence diagrams, again we will be coming back to this later. So for UML, the object classes are rectangles with the name at the top, attributes middle, operators at the bottom. But again, as I say, we will be doing this in detail later, so I am not going to describe those today. So we have covered the finite state machines, these models and the lotus system. The next lecture we are going to be looking a lot more at Petri nets. Petri nets are very powerful and it is worth concentrating because Petri nets always come up and need that. Thank you very much.