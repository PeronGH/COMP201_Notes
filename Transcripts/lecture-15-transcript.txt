[SIDE CONVERSATION] Good morning, good morning, good morning. Today I want to explore a bit more about software design, and in particular look at the main architectural decisions about how you structure your system. Remember, this software engineering one, this module is about building large scale computer systems. We're talking about systems that might have a few hundred thousand lines of code, maybe half a million lines of code. So quite big systems. So we need to get some sense of the overall architecture of the system, breaking it up, not just into classes, but major components. So we're going to-- today's topic is focused on this large scale decisions about what the main components are, how we break that up. And also, I want to look at designing what are termed distributed systems. That is where processing is not isolated in one location. So any processing where the processing is happening over more than one physical unit, that's a distributed system. And the vast majority of large scale systems out there are distributed systems. So it's a really, really important topic for us to consider this. Hurry up. Trying to get sat down. [INAUDIBLE] We're OK now. Right. OK. So we're trying to break up the process into subsystems. And that process is called architectural design. Usually, most students I talk to, they go, well, what do you mean by what is a subsystem? What is it in-- how is that different than just a class or something like that? Well, the architectural design, breaking the thing into subsystems, are system components which can work on their own to a large extent. So you're breaking this computer system up into entities, things that can provide a high degree of functionality on their own and that can be fitted together with other components to make the overall final product. And hopefully, some of those components can be taken and then plugged into new systems without changing a lot of the code, having some degree of interoperability. So we're going to think of how we break the system up into those subsystems and the communications between them. The usual preferred method of communication between subsystems nowadays is using things like web services. So if I have something for doing payment handling, it should be discrete enough in terms of being a computer system that I can put it on a different physical computer than my main computer system. So it could be separate, totally separate. In fact, it could be spread over more than one computer systems in case I needed to handle a lot of payments. Let's say I have half a million payments a day coming in. Let's say it's scaling up and up and up. I need a type of subsystem that I can spread across more than one computer. I can scale it out. If I'm going to do that, I'm going to have to be able to communicate to it in a rather loosely coupled manner. And a way of doing that would be typically to use something like a web service. The control modeling means how the different subsystems talk to each other and who is in overall charge of the computer system itself. And then afterwards, when we take a subsystem, we can break it up into modules. Because we're talking about OO, those modules will be classes. So that's what we're going to be doing in practice. So the definition of subsystem is a system which, in its own right, operation is independent of the services provided by other subsystems. So that means it will work and provide you a type of service. So I just mentioned payment handling. You could have a subsystem for doing messaging. And the messaging one could provide-- I could send into a message and say, I want it sent to this customer. And it would look up the preferences of the customer. It said, this customer likes email and text messages. And it would look up their preferences. And then it would send the messages-- if it was an email, it was sending it to the email subsystem and ask it to go and send the message off. All those nice discrete components. So the module, that's part of the subsystem. And it provides some level of service. But it's not good enough. It can't do a total service on its own. A module in OO will be equal to a class. So that's what we're going to be talking about when we break it up in that respect. But let's have a look at some examples of real world subsystems. So if you're working in Java, they're very often organized as a Java package. So when you do use packages in Java, if you use a package declarer at the start of the package, all of that-- let's say you have one for payment handling. You could have a package and just call it payment handler. And all the code would be underneath that. You could have something for loading and retrieving your objects from the database. There are actually subsystems that have already been developed for that. So there are things like Hibernate, which will do all the database abstraction and allow you to load and save objects in the database without having to write a lot of SQL. It will actually do it automatically. So there's those subsystems available. You might have a subsystem which does all your security. Because security is an application you'd want across lots of your products, isn't it? Anything you can imagine where it's like a type of service that you could then reuse somewhere else, that would be a good idea for a subsystem. Something for doing card payments would be a subsystem. An email service would be a subsystem. That would be distinct from the card payment system. Each one would operate and provide its own level of functionality. Something for doing logging messages. Something for doing financial transactions, something for doing marketing. Something for doing order processing. It would send messages down to the warehouse to say that there was a new order. Somebody in the warehouse would have a PDA. They would click on the PDA. That would go to the order processing system. The order processing system, it might then later on say, this user's-- it hadn't been dispatched, and it said this user's order's been canceled. The person would then get a message saying, you have to then currently cancel this order. That has to be then removed from the picking list. Has to go back to redistribution in the warehouse. All that complexity is enough to warrant a separate subsystem. That's the point of it. It's complex enough, but it's sort of one service on its own. Why is that useful? Because if I do them as subsystems, I can now use the subsystems to build new systems. Instead of having to write all the code again, I've got these components. So I might have a database object relational management system. That's for loading and saving objects in the database. I've already got it, so I'll just use that. I might have a payment system. I'll just use that. I'll just plug it in. I'd spent six months last year writing it. I just plug it in. I add it to my new system. I've got my email system. I've already written it. I just get it off the shelf. And then I add to that my new web pages. This means every time you're doing your development, you just go, I'll have one of those, one of those, one of those, write some new web pages. I've got a new application. I did the same thing again and again and again. It means that this process, this production line of producing software, is a lot more efficient, because we structured it as these rather nicely coupled subsystems. They're all connected just using the network. They're connected using a web service. So that will be relatively straightforward to integrate them together. [BLANK_AUDIO] As you're doing the architectural model, there are a number of things which will allow you to do a model of that process. So remember we talked about modeling when we did Petri nets, use case diagrams, data flow diagrams. Well, we're going to have architectural models which will show you the view of our system. Static structural model will show you all the different subsystems. The dynamic process model will show you how the subsystems send messages to each other, how they work together. Interface model shows you the edge of the system. So that might be written in XML telling you how to interface to it. And then the relationship model, how the subsystems are structured and talk to each other. So the static one just shows you the components, just list them out. The dynamic one shows you components sending messages to each other and processing them. And then the interface model, it defines the subsystem interface. That were typically done using something like XML or JSON, just shows you the messages going in and the replies coming back. And then the relationship model, things like the data flow diagrams within the model. So we want to break up the system, decompose it into a number of interacting subsystems. So we need to think of what our overall computer system is going to do and then break it up into a number of block diagrams. So here's one for a robot control system. It has a vision system. So this has a camera that's taking pictures of the production line. So it has a camera. It's taking frames. It's storing them up, compressing them. It then has a neural net that's doing some object identification. Typically, that has to do two jobs. One is to classify the object. And the other is to say, where is the object? So it has to look at the image and has to say-- so let's say it's like a production line and it's for packaging things. And it's a mouse comes along. It has to say, that's a computer mouse. The start of it's there. The end of it's there. I now can pick it up and put it in a box. Then there's an arm controller. That has to get information about where the thing is and allows it to control a gripper. All these are separate subsystems. So this has a computer system inside it. That has a computer system inside it. This has a computer system inside it. So here we've got a packaging selection system, a packing system, and the conveyor belt control. All those are independent little computers in the production line because everything has a little CPU which controls its operation. The reason why you have them all remotely as separate ones is because you have to have some degree of autonomy to make sure that this thing works regardless of if this network fails or not. So if the network fails, the arm has to be able to operate safely. It doesn't want to keep moving left or right because it did that the last time you told it to start moving round and round. If you sent this instructions and told it remotely that you need to start moving left, panning left, and then you lost the connection, it would just do that all day. You'd have to have something inside it that gives it some sense of autonomy to keep it safe. Remember, the subsystems themselves need to send data to each other. So they can do that two ways. They can either have it in a central database, which is the preferred model for information systems, or for a lot of embedded systems, the subsystem can maintain its own information. So you get that with something like a DVD player. The DVD player doesn't have an external database. It just has all its internal information that's embedded within the DVD player. It has information about what the current time is, and it reads information off the disk, et cetera. So generally, if you're using large amounts of data, as I said, like in an information system, you're going to use this repository model. Client-server architecture, which is commonly used for distributed systems, in this, the distinction is between what's called a client and a server. A server provides service to a client. So requests go up to a server. The server does some processing, might look up some data on a database, and responds back again. And you'll all be familiar with client-server, because you use things like the World Wide Web or email. They're all client-server, aren't they? You kick off a browser. You put in a URL. That URL is then translated to an IP address. The IP address opens up a socket on port 80 most of the time. On port 80, it sends a request for the rest of the URL, including the location. The server takes that, translates it to an internal location, sends you back the web pages after some processing. Then that is rendered in the browser. Then you click on something like that, and the process starts again. This process of backward and forward, the way it moves backwards and forwards as it goes along. So an example of a client-server is something like a film or picture library, for example, something like Netflix or Amazon Prime or something like that. In this, you've got a whole load of services which sit behind a wide bandwidth network. Some of that network will be internal to the organization, and some of it will be the public World Wide Web. Then within this, there is a number of servers. So it will have a video server, some picture servers, something that's serving HTML pages, and then also a catalog server that's used to search for locations based on various different criteria. So this catalog server, again, for something anything like Netflix or Amazon or whatever, they have a massive catalog server that is built by dredging its way through all the information it has on the videos under its request. So now it has locations of exactly where the videos are. And in fact, for most of these architecture, it doesn't just have one layer of video servers. It has layers of video servers that are physically closer to you so that it can cache the latest videos. So that if you're downloading and watching a film in Liverpool, it's not downloading that film all the way from the United States. It's already got a cached local copy. So in these architectures, there's a massive amount of duplication, obviously, of the services involved. But the distinction here is very much between the client and the server in this type of architecture. So the great thing about the client server architecture is it's very easy to distribute a lot of data between a lot of clients. And it means that because you've got a network system and you can scale out, not scale up. Scaling out means getting lots of smaller boxes, not just getting one big, bigger, faster box. By scaling out, it's very cheap to get a highly scaled network. So if you want to add new servers or upgrade existing servers, you just stick them on the network. If you need more network capacity, you just put in more network links. Because it's distributed now, the shared data model is not there. So the different systems might use different data. But there are standards to get around that. You need to put in extra management. So every single server needs some degree of localized management to it. And then you need-- because you haven't got a central register of name and services, it's difficult to find out all the services that are available. The way it's usually done in practice is you have one well-known address, and you go to that. And then that gives you addresses to other address servers throughout. And usually, to make sure that it's redundant, make sure if that server's down, you have a list of usually about 10 central servers you can go to. So if the first one's not on line, you can go to the second, the third, et cetera. Control models, these are related to how the actual control flow moves between subsystems. So control flow is who is controlling your thread of control. So one possibility is you have centralized control. So you've got a core subsystem that controls the other subsystems. The other one is called event-based control. And this, the subsystems respond to externally generated events. Event-based control is very much the model that you have in client server. The server sits there, and it waits for an incoming packet on a port number. And if it gets a packet on that port number, that is considered an incoming event. The centralized control is more to do with some real-time systems, where it's controlling things like hardware, where it has to send messages out to different components. So in the centralized control, you've got a central bit that starts and controls all the other subsystems. So one thing is just to have what's called a call return model. So if you write a program in Java, when you call a method, that method can call another method, and that can call another method. That process starts off with the main part of your code, and that is controlling all the execution of the thread running through that code. So any standard programming language uses the call return model. And that's top down, because it starts at main, calls another method, that method calls another method, that method calls another method, et cetera, et cetera. Every method is controlling the next method in the link. So if you look at that graphically, you've got your main program. It has some subroutines or submethods. Each of those has some other subroutines and methods. And there's an implication here that at any one time, we're only at one point within this thing. So it implies that only one thread is running through that. The other possibility is that you've got different subsystems running in parallel. So they're doing some degree of distributed processing. But then you've got a central manager, which is controlling all those concurrent systems, and can start and stop them, et cetera. So imagine a system where I've got a load of sensors in a factory. I'm reading data from the sensors. Depending on what information I get, I will be then telling it to switch off and on various actuators. You can imagine this, actually, for your security system, for your smoke alarm system. You can imagine you would have a central controller. And then for each of these sensors, you might have something which is reading the smoke sensor. So the smoke sensor itself would have a tiny little CPU. It would be reading the amount. It would be making sure that if it got a very small amount of smoke, it didn't trigger. It worked out what the threshold was. When it got over a certain threshold, it would send a signal back to the system controller. The system controller would then say, oh, I now have to close all the fire doors. It would activate these actuators. And all the fire doors would then close in the building. And all the sprinklers would start. So you can imagine that that would be done by the system controller that would be sending the messages out. Controlling the system controller would be a user interface, which will be a separate process that will be happening independently of it. All of these will be happening in parallel at the same time. So here we've got one, two, three, four, five, six, seven, eight, nine, 10, 11, 12 processes that are all running concurrently. The other possibility is to have something driven by hardware events, generated events. So that happens in things like servers, where they're listening to a port, waiting for you to connect. So for example, if a server is waiting on port 80, it's waiting for an HTTP request to come in. That would generate an event. And that would make a web request happen. But it also happens in hardware. Every time I click this mouse, it creates an event on the USB bus. And on the USB bus, that signals to the mouse driver that I've clicked the mouse. And then it sends a message to PowerPoint that tells it to go to the next slide. That is done by hardware interrupt. Every time I click, that's why it's so quick. Every time a packet is received by a network card, that generates a hardware event. The data is read from the network card into memory. And then a signal is sent to the CPU to say, there's a new packet. Please read it. It's really important. It happens very quickly. You can have something called the broadcast model. And that, different subsystems register with specific events. The broadcast model is what's used in things like web servers. Because they all say, I'm available for web services by opening their port 80. You send the signal to port 80. So now the control policy is not embedded in the event. The subsystem decides on the event of interest. And the subsystems don't have to know when an event will happen. It's going to just happen as it happens. So you can imagine here, these are different subsystems. Each of them have said that they're available for serving web pages on a particular domain. And the first one to get it just responds back again. You could use this to provide some degree of load balancing across a number of servers. Interrupt driven systems, on the other hand, they're used when you must have a very fast response. OK, so as I said before, if I have a network card on the back going into-- I plug a network into the back of a PC, you'll notice that that can deliver new frames hundreds of thousands of times a second a new frame comes in. If that data is not read very quickly, what will happen is very quickly the network card's buffer will fill up and the data will just be lost. It won't have anywhere to store it. So what will happen is you'll just lose loads of data. So what happens in practice is it generates a hardware interrupt. The CPU is stopped for a very short amount of time. And then usually something called a DMA chip takes over, transfers the data into the DMA chip. Sends the data into the main memory of the computer system and then sets off the CPU and the CPU can then go again. So all those packets are moved straight from the network card into main memory. And then the main memory fills full of network packets. And then the stack inside the main memory is then called as part of the interrupt driven routine. That stack for the TCP/IP, the communication stack. So this has to happen extremely quickly. That's why you need this hardware interrupt. So the connections like this mouse or the connector to the network card are connected to a register. And each of those registers is connected to what's called an interrupt vector, which is just an address in memory saying where the code is for handling that type of event. So I've got one for the mouse, one for the keyboard, one for the network card. And as those happen, what they'll do is they'll initiate the handler. So let's say this is the network card. Calls the network card handler, which reads the network data out of memory and then calls the IP stack. Once it gets a fully framed series of IP packets, we'll call the TCP stack. We'll call the HTTP stack. We'll go all the way up until it actually pushes the data to the web server at the top level. When you take each subsystem, you can then do modular decomposition to break it up into modules. So there's two main approaches to that. The object model, which is the main focus of the subject, where the system's broken up into interacting core models, and another one called the data flow model, where the system's broken up into processes. And each of those processes has incoming data and outcoming data as a flow. So the decisions about whether concurrences should be done right at the end after you've done the implementation of the module. So when we do the object model, which we're going to be looking at in more detail in the subsequent lectures, we're going to break up the system into a system of what are called loosely coupled modules. They're going to communicate each other using messaging. The objects now that we have to identify consists of three parts. It's the object class itself, its internal attributes, the data it stores, and the methods and the code it has, the operations. So now, when you do the implementation of this, we're going to create the system from these various objects. So we can think of something doing invoice processing. We've got a whole load of different classes here. We've got a class for the customer, class for the payment, class for the invoice, class for the receipt. Notice these classes here only have attributes. So we've got customer name, address, credit period. These are data classes. Payment has an invoice number linking it to an invoice, a date, an amount, a customer number linking it to a customer. The invoice can be issued to a customer. The receipt can be-- the invoice, a receipt can be issued for the invoice when the payment's been made. So the invoice is sent to the customer. Customer makes the payment. When the payment is accepted, a receipt is sent back to the customer with the customer number on it. The other possibility is to use a data flow model. So this has incoming and outcoming processes. So for most systems, we're not going to be using this because that's not the focus of this module. And it's not considered the best approach to get the highest degree of reusability in the code. But we can think of this. This is similar to previous one. I have invoices coming in. We've seen this similar from what we've seen before. Payments coming in for the invoices. Once we've linked an invoice to a payment, we can issue a receipt to the customer. And then if we find a payment that's overdue, we can send a reminder to the customer. So it's just seeing it as a process model. But we're not going to be focusing on this much for this module. OK, so that's the end of today's session.