(crowd chattering) - Okay, good afternoon. Today's session is the second set of slides about distributed systems. Can you quiet down please? (crowd chattering) Thank you, thank you. Thanks. Okay, so just a review about what we mentioned before. Distributed systems, systems that execute on more than one processor. The processor can be, you can have a CPU itself with multiple cores, that's a former distributed process. You can have a motherboard with multiple CPUs and each of those CPUs have multiple cores. You can have systems separated by a network and have them all interconnected together. With each of those systems having multiple CPUs and each of those having multiple cores within it. So there's many layers to this. But essentially, anything where it's a design, where what you've got software runs on more than one processor. And in general, nearly all large computer based, computer systems are distributed. And that's for many reasons. The primary ones are scalability and redundancy. Scalability then, you wanna be able to make it work for a lot more users, a lot more high capacity. And redundancy, you don't want to have a single point of failure. So those are the two sort of main reasons. And for all information systems, when you're doing that, you have your processing distributed over more than one computer. There are two sort of main models. One is that you are performing the same task multiple times spread over many processes. And that's typically what you have in something like a web service. Where you've got the same type of request coming up from different threads and different people logging in. The same thing's being done and it's spread about. The other one, which is a little bit rarer, or quite a lot rarer, is where you're breaking up a complex problem into many different processes. An example of that would be something like cryptocurrency mining, where you're all looking at a different part of the key space. They're all doing the same thing. They're all trying to solve the same problem. But they've broken the problem up into parts because it takes so much computation power. So in terms of system types, you've got a simple PC, a personal system, which are not distributed in that there is essentially one processor. But even with those, because the modern processors have multiple cores inside them, there is some multiple processing happening even in those. There are embedded systems which can either have single processors or groups of processors working together on a single motherboard. And then there's distributed systems where the separate processors are divided, do not share the same address space, that's an important distinction, and they are connected via a network. They can also, not necessarily, always share the same operating system. So here you can distribute your processing between multiple address spaces, multiple hardware, and multiple software platforms. (audience member sneezes) There's some broad characteristics of distributed systems. So there's this sense that the CPUs are sharing resources, there's a sharing of resources, either between by user processes sharing resources, or multiple CPUs sharing the same memory space. There is a sense that the system is somewhat open, okay, because it has requests coming in from outside of it to do, perform those things. There's concurrency, 'cause they're doing multiple things at the same time. The scalability in that if you need more processing power, if you've got a distributed system, you can just add in more hardware and expect your system to spread itself amongst that hardware. There's fault tolerance in that there's no single point of failure, so if one of the servers dies, the rest of the system can carry on providing service. And then finally, there is transparency. Transparency in that you don't know how many computers you're connected to on the back row. So if you use a service like Google search engine or Netflix or whatever, you don't know how many servers you're connected to. It just looks like one point of service, and you could be, as you move around, connected to many different systems, you still get the same type of service. It looks identical. And that's what's meant by transparency. Just means that the person who's using the service is not aware of how the concurrency is working. That's hidden from behind them. There's a number of disadvantages to doing a system as a distributed system, and the primary one is that it's more complex. There are security issues because a lot of these systems are open, so something like a web server can take service from all over. And that's why you have a lot of problems with things like online banking, because evidently, since it has to be accessible by members of the public and it involves money, then it's obviously a point of attack. You have to deal, you have to manage this process now because you have to manage the scalability. And it's somewhat unpredictable because you don't know what traffic is gonna come down the network. You don't know how much traffic is coming down the network. So you might get a massive rush of traffic at one point, might be very quiet at another. You might suddenly have an advertising campaign on television, and then suddenly your e-commerce web server at seven o'clock in the evening gets a massive huge rush of traffic. That change has to be dealt with in an appropriate manner. There are different types of distributed systems architectures, and we have described these briefly before in the last lecture, but we're gonna go into a bit more detail today. In a client-server architecture, there is a distinction between client processes and server processes. The reason why I call them client processes and server processes is on one machine, like on your PC, you could run a server yourself, and at the same time, you could run a web browser and attach to your own server. So within your one machine, you could have a process that acted as a client, which would be fetching data from a server that was running a server, piece of server software. In a distributed object architecture, the clients are, all the entities, the things, are both clients and server. Now an object can call the services of another object, and it can call that on a remote system. And there is a architecture for this in Java, there is an API called Java Remote Methods. And what that allows you to do is call a method, instead of in the same JVM as you're running in, to call a method in an object that's running in a JVM on a totally different machine. So it allows your program to be split, your Java program, to be split across multiple physical machines, and you can build up a distributed architecture on that basis. So there's a number of them, not just for Java, but there's other ones for languages such as C++, there's other APIs for that as well. There is also software that sits in the middle between the clients and the server, and this is termed middleware. And this typically does the tasks of handling transmissions between the two sides. When I mention that Java Remote invocation, where you're running a Java program on your local machine, and it's accessing a Java class on another, there is something called an object broker that sits in between the two. That will be an example of middleware. So the middleware typically aids communication between the two sides. Middleware is also used widely in things like, oh, things like 3G, 4G, and 5G networks. Evidently, when you have a communication over the, you're communicating your voice signal, that gets compressed highly, and then it gets decompressed as it runs on the broader stream network. It's converted into another form. So that thing of a communication controller or a data converter is another typical usage at this point. The first type of architecture I'm gonna look at is a multiprocessor architecture. So here we've got, this is a relatively simple architecture, and in this, there is a minimum of multiple processes going on, but they don't necessarily have to be executed in different physical processes. So any moderately modern operating system uses this approach. So if you're running on the latest version of Windows, if you're running on Linux, if you're running on any other form of, those are the two main sorts, operating system, there is some degree, there's some sense that there is multiple things happening at the same time. The distribution of those processes to the processor can be determined beforehand, depending on the operating system, or maybe purely under the control of a operating system dispatcher. So in an operating system dispatcher, it sees what processes are ready to run. If you've got four processes, physical processes, it's got four physical slots, it takes the first four, it leaves them running for a while, and then on the next clock, tick of the clock, it will work out which one it wants to take off and which one it wants to run for a bit. And it will do that depending on their current dispatch status. So if they're waiting for a network connection, it might leave it, it decides it doesn't need to run it for a while, if it's active, it will put it into one of the four slots using the dispatcher. And typically, it uses a round robin type of scheduling. That means it goes one, two, three, four, five, six, seven, eight, and then just goes back to the beginning of the eligible processes to run. And here is an example of a multi-processor traffic control system. So here, at the street level, okay, is the traffic light processor. At the traffic light processor on the right hand side here, what you've got is a design which is akin to what we did with the Petri nets. Remember, the Petri nets, we designed something that ran safe and ran remotely. Notice, this is totally autonomous. If this whole thing crashes here, or these network connections get disrupted, the traffic light will still run safely. That's one great benefit of this. Somebody could, there could be a terrorist attack here destroying all this, this, and this, and the traffic lights would still run fine and safely. They wouldn't stop running, okay. The worst that they would do, if they decided they couldn't connect to here and they thought there was an emergency, it would put them all on red to say that, you know, there's obviously a safety thing, you know, because I can't find any communication, maybe I should just go to red. But you can see that this, having this as a separate system, autonomous, has a lot of benefits, you know? It's just not gonna matter if something goes wrong with the rest of the system. The other thing is, is this is autonomous, this is very scalable, 'cause I can add lots of traffic lights on, and they don't need me to control them all day, every day, sending loads of signals, because they're just running themselves. They only need attention if you say, oh, well, there's a lot more traffic going down this road, they could be advised to put the green lights on on different timings, couldn't they, to allow the traffic to get through. Here we have the main display process, so there will be people here who will be actually seeing what's going on. So they would have a view of, they would have a view of cameras looking for the congestion on the roads, seeing if there's ambulances, maybe they see there's some ambulances that need access, they could send instructions to let that road go green for a while while the ambulance is cleared, and then they'd just go back to normal. So they would have a degree of control over it. And then we've got input, which is the sensor processes. So these are sensors on the road showing the amount of traffic. So splitting this up is very, very useful. It allows the scalability, it allows redundancy. But now really, apart from it being more complex, we've really got to design three systems. We've got to design this system, this system, and this system, and then integrate them together. And a lot of computer systems do work like that. You have to design this little bit that works autonomously, that little bit that works autonomously. And that's very typical in embedded systems. If you take something like a modern car, a modern car has a thing that controls the engine, the engine control unit is quite independent of the other bits of the controls on the car, and works very remotely controlling the ignition's timing to reduce the fuel consumption, to be able to improve the performance, things like that. The next type of architecture, which is typically used for a lot of information systems and distributed information systems, is the client server architecture. In this, the client servers, instead of being physical things, are what are called logical processes. That means that within any computer system, you can have many servers running, providing services, and many little clients running at the same time. So the mapping of the processes onto the process is not necessarily one-to-one. Here we can have many processes working on a single processor. So if you look here, I've got physical server one. So these boxes, they represent the hardware. So I've got physical server one, physical server four, physical server two, and then we've got some client processes running on these, accessing these servers, making requests to them. So server one is providing service for client one, client two, client three, and client four. You notice we've got multiple things, and these are the server processes. So this is the process view of the client server system. When you map that to the physical hardware, you notice now the servers, they can support more than one server process. So this server computer here, SC2, is providing services, the processes, S1 and S2. That could be, for example, a web server and an email server. It could have a file transfer server. Could have a whole load of different servers. You could put 20 different services in there. And again, for this one as well, here on a client, I have multiple client processes. So I could have, this first client could be me running Chrome. The second client could be me running Safari and the same computer. And the third one could be me running an email client. The way it works out, how to port the traffic from clients to servers and back again, is it uses a special number called a port number. Okay, so the servers, for example, for HTTP, they listen on port number 80. And then when a client opens up a web browser, puts in the URL of that server, the TCP packet has port number 80 in its destination address. It arrives here and it knows to then route it to the HTTP servers. If it has number 25, it knows to route it to email, etc. So it uses those to route. And equally, routing back, when you've got the traffic coming back to your laptop or your PC and whatever, when you've got a packet coming back, it has to know if that packet was from this version of Chrome. So you could have two instances of Chrome and Safari running. And you can have email running all at the same time on your computer. Each one will have a separate port number coming back. And since you have over 65,000 port numbers, you've got plenty of ability to multiplex on that. So that's the way it's done in the client server network. In general, the architecture for networked applications consists of a number of layers. And the reason it's broken up like that is to simplify what is really a very complex task. So at the top layer, we have the presentation layer. And that's concerned with presenting things to the user, the end user. Then we've got, so we're going to, so this will be, if you're dealing with something like a web application, the presentation layer would be all the code that supports the output in the browser itself. The application layer, that's concerned with the business logic. Okay, so in a banking system, that would allow you to transfer money between accounts, doing the nuts and bolts of it. That's called the application layer. And then at the backend is something which stores all the data persistently and allows you to do searches across the data, is the data management layer. Typically, for a lot of applications, the presentation layer is done using some type of web service. The application layer is coded in an active scripting language. It could be done in Java, it can be done in Python, in Node, in PHP, loads of options there. And then the backend, the data management layer, that's where your database is. So the language used there would be something like SQL. It could be SQL, you have other options for no SQL databases as well. So they're all broken up into these three parts. So when I make a request, I click it in my web browser, I would be making a request at the browser level. That would send a JSON request to the application layer. That might then load up some information off the database and then send me a new webpage, and that new webpage will be presented back to me. So by breaking up into those parts, it simplifies the architecture of the software. It helps to design it. There are two approaches to systems. The first of these is the thin client model. And in this, all the processing and the data management is carried out on the server. For a lot of modern systems now, this is generally the preferred architecture. In that, you do, if you connect to anything like a service like Gmail, or you connect to, you connect to any service that's provided by the web, what's happening on your client locally is not the main part of the processing. It's mostly just presentation. In the fat client model, you have an application in the client that is sending requests to the backend that's doing some of the processes. The fat client model would be a model more akin to something like a mobile app running locally, and then that does some local processing, and then sends a request to the backend. So you can see that here in the thin client model, the client itself, the front end, is just doing the presentation. So that'd be an example if you had a web browser, that would be doing it this way. In a fat client model, some presentation and application processing is done here within the client itself. So in general, for modern systems, they're generally not totally thin or fat, so they're somewhere between the two. So even with a browser, when you use a browser, it's somewhat thin. Some browsers have very complex client-side code in it. So one example of that is if you had a game that was written for a web browser, now that could be a really complex piece of software, it could be a very deep piece of software, it could use optimization. So there is some processing done, but anything that's done that has to be somewhat mission-critical, i.e. for a banking application to handle the accounts, all that sort of stuff, that has to be handled upstream. That's to be handled in at the top end. If you have an app, again here, the app can be thick or thin depending on what it's actually doing. So for some, for example, for some like, you get some for like banking apps, a banking app is generally very thin. It's just a way of presenting the information in such a way that they can be sure that when you're accessing the app, they know that you're fully authenticated. So sometimes, has an extra layer of authentication built into the app to keep that a lot tighter. So it could have things like, that could communicate with your card, and then you could put in your PIN number to make sure it verifies who you are. So generally, the backend has to do quite a bit of processing. And it has to do quite a bit of processing because you move yourself from client to client every day. So at one point, you'll be using your banking app on your phone, next moment you're using it on your computer. You have to have the same view, don't you, of the backend. So we can think of an ATM system as a bit of a client server because any ATM acts as a client to the main ATM system which accesses the user's accounts. So when I put my card into an ATM, even though the ATM is a fairly fat client, I mean, it has to be able to do things like keep itself safe, stop people stealing the money out, has to be able to deal with security issues such as reading the card and dealing with the PIN number authentication protocol, has to do that in such a way that's secure. So in this, it's a client server architecture, but the ATM itself is a pretty fat client. I mean, it's a huge thing. It's a massive box, isn't it? Has quite a bit of software within it. A lot of systems now use what is termed a three-tier architecture, and that's useful because it's a very scalable architecture. So as the demands on the system increase, go up and up, you can add extra layers to the different parts of the system. It's very, very scalable. So let's have a look at how that works in process. In a three-tier architecture, we have a minimum of three physical computers. You have the client itself, okay, which is just what you're accessing. So that can be your mobile phone running an app, or it can be a computer running the browser. Then you have a server running the application processing. So this could be PHP, Java server, C# server, could be a whole load of other things. You could have it running Java Spring. You could have what's popular now, Node. Could be a Node.js server. So this is doing the application. And then at the backend, we've got our database. Now what happens is if our application processing, if our clients are running slowly because the database is overloaded, I can just add in more database service. If this is running slowly, but the database is not overloaded because it's not a very data-intensive application, but I've got the application processing is running slowly, then I can add in more application processing. An example of that would be something like Instagram. Instagram uses things like filters, doesn't it? When you do a filter, you have to send it up and then an awful lot of processing goes on. That's not data-intensive. That's not database-intensive, but it is CPU-intensive. For something like Instagram, well, they've got massive data management as well, but if they find it was running slow, but they found that they've got plenty of data access, they'd just add more application boxes. They'd just add more of them in. So it's a nice architecture 'cause it's very scalable. So an example of that, the three-tier architecture, is an internet banking system. And in practice, this middle layer is generally always now a web server. So this is the preferred middle layer of the three-tier architecture. To connect to that, you've got all your clients, and they're gonna make a request on port 80 to request one of the internet banking web pages to log in or do an update on the account. Once that's done, let's say you're logging in, has to look up your customer number to get the password. The password comes back. It checks that you've accessed the password correctly, and then it sends a response back with the new web page carrying on and on and on. So for most modern web applications, you have a minimum of three layers. On some architectures, you have more because you have this idea of load balancing architectures, highly redundant architectures. So for example, if this was a load balancing architecture, I would have something between the client and a number of web servers, which would send my request to the appropriate web server depending on their current load. So the architecture can get more complex than this depending on how big the system is. But that's the minimum, the absolute minimum is these three layers. So in summary, we've got these simplistic two-tier computer systems with the thin clients. You've got the two-tier computer systems with the fat clients. And then finally, you've got the modern system, which is the one that's essentially used now, but somewhere between these two, where you've got three tiers because it allows you to scale both the data and the application as you're moving forward. The other type of architecture you can have is called the distributed object architecture. And in this, the client and the server computers, there's no strict distinction between them. So now we can have an object that has methods, and those methods can be called by code in other objects which exist on other computer systems, and they can call systems on other ones. There is a middleware system in this called an object request broker that channels the requests from one object to another object when it has to go across the network. So they're going to be a bit more complex to design than client-server systems because at any one time, you could be communicating with objects that could be on many, many other computer systems. So your one object here could be communicating with 10 other objects, can split it up. So here is a diagram of that, how that works in practice. So here I've got object one, which provides a service of server of object one. Now object two can make a request to object one via the software bus, and the software bus where the object breaker, that marshals my call. So I call a method in here, it maybe returns some data in here, and then the response is channeled back again. So this is a lot more complex because now any object can be accessed by any other object within the computer system, but it is very, very scalable. We look at another architecture which is an extension of this called the actor model in software engineering two, which provides you a very broad scalability of this type of application. This type of architecture and the actor model extension for it is the type of architecture that's used for Twitter. So Twitter uses this idea of a distributed object architecture because it's highly scalable and it's good for high-speed messaging. So now we don't have to say where the execution is going to be happening before we start. We don't have to make that distinction between server and client. And because this is a very open architecture, now as we want to add services on, we can add them on in any computer. So we can just say, add this on, add some more services on, add this on. And we can distribute a complex problem over a number of nodes. So I said the example before where you were doing something like, oh, doing mining for cryptocurrency would be useful for this. Something where you were trying to crack an encryption algorithm. Anything where you had to spread a very complex problem over a wide number of machines. Things where they're doing, oh, working with genetics now. There are times when you're dealing with very, very large amounts of data and you're doing very complex computational problems and you need to spread it across a lot of machines. This would be a very useful approach to that type of problem. Because it's scalable, you can just keep scaling up and up and up. So it's very flexible and scalable. You can keep adding in new objects. So it doesn't make any difference to the current ones. And it's very dynamic. So let's say you suddenly need to add an amount of computation on. You can do that by taking an object and then migrating it, moving it to another place. So let's say it's working in an environment where it's fine. It's not got enough CPU power. It can be moved to another CPU processor. So we've looked at the client server architecture. So that's very important because it's one of the most widely used for information systems. And we looked at how the user interface runs on the client. That's the front end. And the data management is on the back end. We also looked at this three-layer architecture. That would be the preferred approach for you, for example, if you're doing your group software projects, you're doing a web service. That would be a typical way that you would design that. And then we looked at doing this-- the implementation of the functionality can be done on the client computer or the server. But as I mentioned, more and more of this is pushed more towards the server on a modern, typical system. We looked at also this distributed object architecture, which is useful for things where you have to have high degrees of scaling. And we also mentioned the application of middleware to allow the different objects to talk to each other. [SIDE CONVERSATION] [BLANK_AUDIO]