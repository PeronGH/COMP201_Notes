[SIDE CONVERSATIONS] OK. Hello, good morning. So at the end of the last session, you should have completed enough now within the lectures to tackle coursework 1.1. So I suggest you use the tutorial sessions to get seriously stuck into that. And use them if you need any help to ask the tutors-- ask the demonstrators to some help with it. OK. Today's session is going to be carrying on talking about requirements engineering. And in fact, we're going to spend a bit of time talking about security requirements. Because a lot of systems-- nearly all systems-- need some degree of security. So we're going to look at the processes involved in requirements engineering. OK, so requirements engineering means getting the requirements, understanding them, and putting them in an effective document in such a way that those can be used as a basis to design the software. And/or possibly pieces of the hardware as well. It's not always clear at the beginning where the boundary between the two is. It's worth noting that certain things that used to be done previously in hardware is sometimes done in software. And vice versa, things that were done in software are now implemented in hardware, depending on what's available. So something like neural nets-- neural nets are now done in software. In the future, people will have neural net chips. And that's the way you'll go. Because it'll be a lot quicker. You don't want to be doing it-- you know, doing it software. You want to do it hardware. We're going to look at how we elicit requirements. "Elicit" means to obtain. It means to get the requirements from a given domain. We're going to look at how we validate requirements, determining if they're any good or not, and how we review them. So when you're doing your group software projects, when we're doing your group software projects next semester, you will have to be spending quite a bit of time getting your requirements correct. It's part of the assessment. And then we're going to be thinking about how we move forward with modifying the requirements as the system evolves moving forward in time. So the process, how we're going to be looking at the requirements, vary depending on what the application we're doing them for. So if we are writing something like a game, it's going to be a lot different requirement solicitation than if we're getting something, for example, for a health care system. But there are a number of what are called activities that are common to all of them. Those are called the generic activities. And we'll be looking at those in some depth today. And the goal, the outcome of this whole process, is to produce a systems requirements document. So your coursework 1.1 is a systems requirements document. It has descriptions of the behavior of the system, what happens in unusual circumstances. It also includes the non-functional requirements of the system. So that is an example of a systems requirements document. So the first step is to do this thing called requirement solicitation. And that you talk to the end users. And you need to talk to the end users of the system because only they know what they want the system to do. You need to find all the different stakeholders. Then we go through a series of analysis. And we classify and prioritize, work out what are the most important requirements, and negotiate them. Some things may be possible to do with the given budget with the amount of money. Some things might not. That's what I mean by negotiate. You're going to have to work out which ones you're going to include and which ones you're going to exclude. You typically, when you do the elicitation, people will ask for a lot more than is possible given a particular budget. Then you've got to look at the system you propose and see if it provides what the users require. So you have to say, we've described the system. We passed that document back to the users and say, is this what you required? And they may say, well, no, we didn't like that bit. I think there's been some misunderstanding. And then as time moves forward, we need to manage this process. And we need to manage the possible changes to the requirements document itself. So obviously, next year, if we do a tax system, the tax rules change next year. If we have a medical system, there are new treatments available. You might have to change the system to make it adaptable for a given environment. So for example, these are the steps involved in the elicitation and the validation. So first step, elicitation, actually talk to people. So this is a patient medical system. Talk to some patients. Talk to some doctors and nurses and receptionists to find out how they do it currently. So they may already have a partly computerized system. They may want a system that's actually capable of working with handwritten notes. Not necessarily everybody wants to type stuff in. Have you got the capabilities of doing that, to actually working out what some handwritten notes are? There may be a legacy of current data. There may be a whole load of documentation. There may be a load of notes on patients that are already in a paper form that would have to be imported into this new system. That could be very costly. You'd have to work out to do that. You have to consider Data Protection Act, legal restrictions. You have to think of what the problems are with the current system. Maybe people are not turning up for their appointments. Have we got any security issues? How are we going to make sure that people can't see somebody's very private medical history? And there will be costs involved in all of this. The next step in elicitation will be to start writing some draft documentation and review it, and work out what it's going to cost. And then also work out whether you need any new hardware. So you might need new hardware because you want to have the system more secure. You might want little security dongles. Then if we're validating this, we send those requirements back to the end users, and then go back to step one. So evidently, this is somewhat iterative. It will require a few goes around the loop. Then as you're managing the system as you're going forward, you can have a yearly review. So you go back to the stakeholders after a year and say, do you need it to do anything else? That we suddenly-- we have a new cost budget. We've got 5,000 pounds to add some new features in. We can add in some new pieces for it. And then you see whether that's possible, and then add them into the system. The first step in any project is a feasibility study. A feasibility study is whether it's worthwhile to actually do the project. So it's a very short focus study. So it looks as if the system asks if that contributes to the objectives of the organization. So if it's a medical clinic, its objectives will be to keep the patients healthy, to have a organized schedule for the doctor's appointments, to make sure that people turn up for their appointments on time. So it might need some reminder system. To handle all the inoculations, to make sure that everybody has their inoculations at the right time. That might be one of the organizational objectives. Work out if this can be done, what we're going to propose in terms of a system, using what technology we've got, or if we haven't, whether we're going to have to buy some more. And whether we can do that within the cost constraints. So obviously, it's no point in proposing a new system if you haven't got enough money to develop it. There may be other systems that it has to integrate with. That might add to a cost as well. So typically, very often for medical systems, people will go to a hospital for certain tests. The results then have to go back to their local doctor. There is some degree of integration between systems then. And sometimes there's a simpler way of doing what you're trying to do. So you might buy in the software and customize it. But whatever happens, the feasibility study is going to say whether you're going to go ahead with the system or not. Understand what the requirements of the medical system are and what the services it needs to require. So it's going to require some interviews. You're going to have to chat with people. So you're going to have to chat with the end users of the system, the managers of the organization, anybody who is involved in maintaining the system, and then people who work as domain experts. Anybody who is relevant to the system is called a stakeholder. So when we did the hotel booking system, remember we talked about having the accountant, whether you want to have the tax inspector, whether it would be able to produce a decent report for that. The hotel, the people who did the cleaning staff in the hotel, they would be stakeholders because they got affected by how the system was developed. So these are the stakeholders. And it's very important, if you don't get all the stakeholders, you may miss some functionality that's required of the final system. In general, a lot of stakeholders are not particularly clear of what they want of a given system. So for example, if you think of a stakeholder who's a cleaner in a hotel, all they want to do is be able to just know what they're doing each day. And the order that they clean rooms is not going to affect their life. But if you think of somebody working on the receptionist, or the guest, or the manager of the hotel, the order that the rooms are cleaned in is absolutely critical to making sure that when guests move in, they have a clean room. So you would think that clean room, if you think about that as a requirement, people might think, well, the stakeholder would be the people who clean the rooms. But actually, there's loads of people who are stakeholders in that. So by seeing the views from different stakeholders, you get the requirements correct. And sometimes stakeholders have conflicting requirements. So staff want the system to be very easy, simple to use. But the management might want very, very high security. If they have high security, it means that all the staff might have to have security cards that they put into the system before it enables. So it might not be so easy for the staff, but it's a little bit of a conflict. If you're thinking of a medical system, the patients might think, oh, I've just decided tomorrow I want to change my appointment easy. That might not be good for the clinic, because they may end up with an empty appointment that they cannot fill at that short time. So in terms of planning and resourcing, patients changing appointments easily might be problematic. It might not make the system run. It might make the clinic run quite poorly. There are organizational factors that we're going to change the system requirements. So data protection might say that none of the reception staff can look at the full address of somebody, even if they'd want to, even if they thought it's appropriate. Maybe they want to send them a Christmas card or something. But it breaks the data protection legislation. And then as you go through the requirements process, you may have new stakeholders. And when you have new stakeholders, you very often have new requirements. So once we've done some elicitation, now we need to gather that information together and some possible models and find the user requirements from that information. So we've got documentation. We've got the stakeholders. And we might be looking at a specification of a previous system that's similar to this. Very often, if you're working in your-- for example, if you're doing your final year projects and you have a proposal to do a game, it's often a good idea to look at similar games. In general, in the real world-- so you'll see I've got quite a few of these slides where it says, in the real world. It's because this is really important to understand how this happens in practice. Requirements very often come from modifying and working on previous requirements above the previous systems. So you look at an earlier system. You look at their requirements document. You go through it. You go, oh, well, this is quite similar to what we want. It's got some really good features in. We're going to borrow some of those features. You might be looking at a legacy system. So you might go into the medical clinic, and you might say, what's your current system? And they might say, well, it does this, this, and this. But it hasn't got all these features in. And you can say to them, well, we'll do all that. And then we'll add on those pieces. That's another good approach. Because obviously, they've got something they're familiar with. So there's two things here. It's a computer system that's good for them, but a computer system that's easy for them to use. Well, they have certain similarities to the previous system. That's a good thing. So a legacy system. And then you can look at what competitors are doing in the market. So you can't copy certain things. You can't just copy identically things. But you can use the same features as someone else. There's nothing in terms of features and requirements that's copy-writable in that respect. The other thing you can do is you can produce a prototype. So the prototype is just a roughed up version of the user interface showing the customers what the system could possibly do. So some quick look at that. So if we had an ATM, the stakeholders could be fairly ranging. So anybody who's a customer at the bank would be an ATM stakeholder, because they get affected by how the ATM works. You could have people who work for other banks. The reason for that is that very often when you use an ATM, the ATM is owned and managed by a bank who you're not the customer of when you're using the ATM. You're using an ATM from another. They have a network of machines, and they have to interoperate with other banks, don't they? So if you have a NatWest bank card, you can put that in another bank's ATM machine, and they're expected to communicate with one another. The manager of the bank could be a stakeholder, because it affects them. They might have to manage the ATM machine. The counter staff might have to fill it up with money, and they might have to monitor it and manage it. Somebody who's working in the database or the security managers, they might be affected by it. The marketing department-- now ATMs very often have advertisements on the ATM when you go to it as advertised, so they may be involved. The people who have to maintain the ATM machine-- the reason why they're stakeholders is the ATM software will typically have to tell them if something's gone wrong. So all these systems, they have what's called self-test features. And all the time, the ATM machine is testing all the parts of the ATM machine. If something goes wrong with it, they shut it down so that it doesn't go wrong and give loads of money away or steal people's cards or cause a load of problems. And then finally, if you're working in banking, then it's a highly regulated environment. The banking regulator would be relevant. Those stakeholders lead you to a series of viewpoints. And the viewpoints are how you can structure the requirements to show you how the requirements look different from different stakeholders. So when you do your alarm system, when you do your fire and smoke alarm system, one viewpoint would be the viewpoint of the fire brigade, one viewpoint would be the viewpoint of the police. So different stakeholders are different. So different organizations or whatever are going to have a different viewpoint in terms of how the system's meant to work. So one thing the fire brigade and the police would not like would be too many false alarms. And they may have a system which shuts your system down if you send it to them. It might say, oh, we can't deal with this. We're going to have to shut off your service. So you're going to have to make your system sensitive enough that it does not create that situation, that functionality. So it's very important that, because there's not a single way to calculate, analyze system requirements. So from a user's point of view, you'd want the fire alarm to be very sensitive, because you wouldn't want it to miss a fire and cause a fire in the building. But as far as the fire brigade's concerned, they wouldn't want it too sensitive that they get false alarms. Every time somebody puts some toast on or something like that. So as far as the fire brigade's concerned, they would want a higher level of fire, a higher level of fire alarm, maybe some sort of thing where it's teared up in terms of the severity of the problem. So the viewpoints, the way you're going to be looking at these, vary depending on where they're coming from. So it can be people who provide and receive the services of the system. It can be other systems that interact with the system you've got. So for example, maybe you're interacting with PayPal, or you're interacting with Google Pay or Apple Pay. Those would be other systems that interact with the system. There may be a viewpoint in terms of regulations. So the Data Protection Act or the payment card regulations. And then you can think of the non-functional requirements in terms of what the business requires. And then there are the people who have to develop and maintain the system. So for your fire alarm system, you would want a test feature where you could press-- where you could say, tomorrow at 10 AM, we're going to have a test drill. And we know that the fire alarm's going to go off at 10 AM. And we're going to program that into the fire alarm, because we need to be able to check that everybody knows what the fire regulations are. And then a way of testing the system. So you'd want to say, well, we want to test the smoke detectors, but we want to be able to test them in such a way that's easy to do. There may be marketing viewpoints. One approach to working with stakeholders is to interview them, is to ask them questions. So here, the requirements engineering team, they're going to ask the questions to stakeholders about the system and what they want it to do, what new features they want. In general, there's two approaches to interviews. So the first one is the closed interview. So that's where you've got a load of questions, and you just say, well, what do you think of this? What do you think of your current system? Are you-- are there any problems? When you get in-- when you get in the first thing in the morning, what do you do? What's the last thing you do at night? What problems do you have with patients not turning up for their appointments? What do you do in that case? Do you follow them up? Do you call them? Do you ask if there's a problem? Do you put a note on their file, et cetera? In the open interview, it doesn't have that kind of structure. So sometimes, the open interview is what's called a focus group, where a load of people just sit around, and they chat about the problem. And you make a recording of it, and then you look at it later on. So you're not there. So they can discuss it openly. So generally, if you're interviewing, you need to listen to the stakeholders and not have a fixed idea of what the system's going to be. One approach to doing this type of analysis is to use something called ethnography. And ethnography, it's a social science technique developed to look at how people actually interact with each other. So one way of doing ethnography would be to have an office where people are answering the phone. Let's say they're answering calls for queries about their bills or something. And in this, you record what they're doing. And then later on, you see how they interact. So when they've got a problem they don't understand, they may contact their boss, et cetera. The good thing about ethnography is you don't ask them questions. You just see how they're doing their work, and you analyze it. So it has that benefit. So now you're going to pick up on little things which you wouldn't pick up. That they just assume that you can observe they're doing, but they didn't even know they're doing. So little social organizational factors, the way they work together. So what's good about ethnographic studies is it shows the work is a little bit deeper than suggested by simply talking to people and modeling their how the data is flowing. There's more going on than you think. And the other one is to use something called focused ethnography. So in focused ethnography, you do some prototyping of the system, and then you get the people to use that new system and see how they interact with it. So this was developed originally in a project studying air traffic controllers. So in air traffic control, you've got a load of planes in different sectors. When a plane's in a sector, it has to be at a given height away from other planes. So two planes in the same sector can exist in the same area, but they have to be separated by height. As they move into a new sector, they have to adjust their height if there's a plane that would be in that height range in the new sector. That's essentially how air traffic control works. And it works by the plane being 5,000 meters up in this given area. And as it moves into a new area, it might find that the 5,000 meter height is taken up. It gets moved up a level. If it can't, if it's jammed in that area, what it has to do is it has to circle around and around that area until a gap is found in an appropriate height in a next sector. And then it might have to change. It might have to take its height down or take its height up. Just to separate it from other planes, that's all you're doing. You're just keeping them, essentially, from bumping into each other. That's all air traffic control does. It sounds very complex, but it's actually very simple in concept. So in this, you use a prototype and you look at the-- you do some analysis by seeing how people work. The only big problem about ethnography is studies like an existing practice. So now we want to look at how people are going to operate with the new system. So that's why we introduced the prototype. So now, because we're using ethnography, we can see how people actually work in practice. So when you're doing with the air traffic control, they used to have things where a plane would be coming into your sector and you'd get an alarm. A buzz would happen. What they used to do is they used to just-- they used to say, oh, well, I know that one's coming in. And they would disable the buzz alarm so that it wasn't then distracting them all the time from actually doing their job. So there's some shortcuts that are evident. So in the air traffic control, as I said, the conflict alarm saying that two planes, if they carry on in that thing, they would bump into each other, that may be switched off once the plane has then been informed that it has to change height. So it might not have changed height yet, but it has had the message to say that it's changed height. And it will repeatedly get that message for as long as it doesn't change height. So they wouldn't leave the conflict alarm running. Obviously, it could then reopen the conflict alarm if it was getting closer, depending on the thing. But here we need-- because the alarms are distracting. So weirdly enough, even though air traffic control seems like something, well, you think you could computerize that, in fact, air traffic control still has people who are managing the flow of the plane. Still people are responsible for the height and the sector of those planes. Because there is a certain amount of nervousness allowing a computer system to make those decisions. Because if the computer system gets it wrong, it's very difficult to know what you're going to do at the end of the day. You're in big trouble, aren't you? The thing about ethnography is the requirements that are derived from how people cooperate together. So you can use the computer system to help them work better together. So if you're using anything like cooperative team building, using things like source code control, or you're using things like feature management applications and project manager applications, they work by helping you to work together with other people. So when you develop those applications, they should be improving the communication. Because you don't work in isolation. You work with other people. So with an air traffic controller, there's a certain awareness that colleagues get. Because they work together within a sector. So you'll have a load of people. They'll have one air traffic control office. And they'll all be controlling a given sector. And they can talk to each other. They can say, I've got this plane coming in. It's at this height. You're going to have to manage it. So that type of communication. And they might say, we have a few coming in. I've got one coming in at 10, one coming in at 10, 15. Needs managing. OK. A major part of most computer systems is to have some degree of security. So all modern computer systems have to have security. And that's because they are very often open. So they're open to the internet. The systems very often control very valuable things, such as money and data that's valuable. So very often, the data's personal, valuable. And there are legal requirements to keep your system secure. If you don't do that, you could get sued by the people whose data is lost. Or, of course, if finance is lost. So the security requirements of systems are broken into four big issues. OK, so the first of these is confidentiality. That's keeping things private from people reading it, but within a reasonable time scale. So if I encrypt something with a 256-bit password, it may be possible for that to be cracked in 200 years. But I don't really care in 200 years, because whatever data was in there would be totally irrelevant. If it was a credit card, it would be expired 199 years ago. And if it's confidential data about somebody, well, they'll be long dead. It's not that interesting. So the important thing about confidentiality is confidentiality up to a point. And that point is usually some time in the future. OK, it cannot be always kept perfectly, because you can always crack keys. You can go through all the combinations. It's quite possible to crack them. The next one is integrity. That's the ability to stop a message being received in error without you knowing that it's in error. So you send an email to somebody. Somebody can change the email, but you know the email has been changed. So it's not necessarily the case that you can stop the email being changed, because data's on the web, or it lands up in a server and somebody can just edit the information inside. But you can guarantee that you cannot change it without detection. That's really important. Next ones are authentication and authorization. Authentication means proving to the computer system who you are. OK, so there's lots of different ways of doing that. I'm going to go into that. We're going to pick that up in the next lecture. I'm just introducing this topic. Authentication is proving who you are. OK, that's all it is. Authorization is slightly different. That is controlling what you can do depending on who you are. OK, so if I'm working on the hotel management system, I can't put in a new cleaning rotor unless I have the right authorization. And you see authorization. You commonly get it in file systems. So in Linux, there's user group other permissions on files. Windows uses a slightly different structure. It uses something called access control lists. In fact, ACLs are also available in Linux now as well. ACLs are a little bit more-- what they do is they allow every single file to have permissions applied to it for every single different user at different levels. They're very, very flexible. But they're more complex to understand. The next one is called non-repudiation. And non-repudiation is probably one of those ones that a lot of people wouldn't necessarily think of. They've not heard of it before very often. Non-repudiation means I can send you a message, and I can confirm that I want you to do something like buy some shares, or we agree to a contract, and whatever. And later on, I cannot deny sending you that message. Later on, I go, oh, I didn't send you that message. And you go, well, I've got this non-repudiation service in place. It proves that at that date, at that time, you sent that message. Non-repudiation is very important if you're using computer systems to do financial contracts and financial relationships. Because you need to prove that you agreed to buy something at a given price at a given time, and it was you agreed to do it. That kind of thing, like a contract. The final one that we're going to look at in the next session is something called availability. And that is just the ability of the system to stay up for 24 hours a day, seven days a week, all year. And availability, even though you don't think of it as security, it's security of service. It's the ability of the system to do it. So if you've got the ATM system, you expect to be able to go down to use that ATM system. You don't expect it to be not working at 2 in the morning, consistently. It's a really important thing to be able to get money out when you can or do transactions. Availability is obviously vitally important for any safety-critical system. So if it's safety-critical, if you are driving your car, and suddenly the car says, oh, I'm just going to reboot the software, and you're doing 70 miles an hour, it wouldn't be a joke, would it? It could be really dangerous. So availability is really important for a lot of systems. That is becoming more important because systems are becoming more critical. But I'm going to go through these. We're going to talk about these in the next lecture and how we provide them, et cetera. Thank you. I just want to pick those up. [ Silence ]