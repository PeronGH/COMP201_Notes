[SIDE CONVERSATION] OK, good morning. This is the last session. I'm taking this because Henry's going to the dentist. Today's session is on software cost estimation. OK, purpose of software cost estimation is, believe it or not, to work out how much it's going to cost to do our development. And it involves a number of estimations. It involves estimating how much software is going to actually be required to be developed. Obviously, that's quite tricky. And then converting that estimation into some costs of how much time will be required in terms of development time from that size of software. So all the resources that's required to go in. So how much effort's required to be complete in activity, usually measured in person months. So if you have five staff working 10 months, that would be considered 50 person months of effort. That's typically how it's measured. The other thing you might want to know is how long the project's going to take to complete. And you want to do that, provide it as part of a proposal. And then the final cost of an activity. If you haven't got the final cost, then when you draw up a contract, you could be losing money on the contract. Or if you overestimate the amount of cost, you might not win the contract itself. So the process of the estimation and the scheduling are interleaved activities. That means as you're working through the project, you'll do an initial estimation. And then after some development work, you do some requirements analysis, you may do some more estimation and more scheduling. And the reason for that is that as you work through the project, you find out more and more about what's involved in terms of amount of development. So after you've done the design stage, obviously you've got a clearer view of what software modules you're going to have to create. So Henry will have gone over the development of the class diagram and the modeling. Once you've done that, then you can see what software modules you require. Evidently, the estimation's going to be easy as you come in. As you have the initial requirements analysis, just the draw up of the first thing, like the thing you've got for the fire alarm system, at that stage, it's quite difficult to do the estimation because you don't have much information. So there's a whole load of components that go into the development of software. And the initial ones are the software and hardware costs. So if you have to buy some computers or you have to buy in some bought software, typically this is a small part of the final cost. Very often the software's already there, or it's freeware, or it's open and available. And hardware is considerably cheaper than it was. There may be costs in terms of traveling to sites and getting the staff trained up. And there will be typically-- the core costs will be the amount of effort. So the cost involved in just employing developers and paying their wages for the progress of the project, and then any other extra costs on top. So those will be typically the core costs for your work. But there will also be overheads. So there will be the costs of renting, paying for your building. These are obviously-- you have to pay these all the time, whether you're doing your development or not. And the costs of your data communications, any extra facilities, any staff restaurant. For these reasons, this last block, a lot of employers now are trying to reduce by doing more work from home. After the pandemic, it made a lot of sense. You find a lot of that. You'll see a lot of job adverts now. You can work, spend quite a bit of your time working from home. And the reason they can do that is development can be done anyway, can't it? Take your laptop back. It's quite a good idea. So these costs can be trimmed a bit, particularly in terms of the final block. The important thing about doing the estimation is it then allows you to get the cost of producing the system. And in general, there is not a one-to-one relationship between the development costs and the price charge. So if you just take the development cost and add a bit on and say that's the price you're going to charge, that's called cost sand. And that type of thing is a very old-fashioned view of how you do pricing. So pricing now is generally done on what the market can bear for any particular environment. So you may, for example, if you're doing development software for the NHS in doing medical equipment, you have to have a special certificate and license to do that before you're even allowed to start working and competing for those things. Because of that, that allows you, because it's a constrained market, that allows you to put your costs up a bit more, because it's a difficult area to work in. There's not so many people. So there will be market reasons why there's a cost difference. So for example, you might want to, if you want to get into an area, quote, "a low cost." You might want a loss leader. There might be a degree of uncertainty in terms of the estimation. So if the thing's a lot more uncertain, you might want to add a contingency to the cost. And there may be contractual reasons that you are willing to either lower or increase the costs of a given project. So this one, it says, "may be willing to allow the developer to retain ownership of the source code and reuse it in other projects." That is not very common. Typically, if you develop, if you as a company develop source code, what you do not is you do not sell the source code to the person you're writing the project for. You sell them a license to use the source code and to use it in the project that they get. So what they get is not the code itself, but a license to use the code. That's quite different. So if you're willing to provide them the source code, typically you can charge them the same amount again. If the requirements are going to change a lot, that might be difficult because it might mean that after the contract's awarded, then the costs will go up as the project runs through. And then there may be a circumstance if the developer is in a difficult financial situation, they may be lower their prices. When you're doing the costs, it's very important to know what your programmers can actually produce in terms of numbers of lines of code or amount of development per week or per day. Because that's the only clear way that you can get a relationship between the amount of effort required for the project and the cost that will be involved in terms of engineers' hours. So the only issue to do this is it's not orientated particularly around some degree of quality. So you might have a software developer that can produce a lot of code, but it not may be very good quality code, or it may be code that's full of a lot of bugs. What you want to know is not really the amount of lines of code they can produce, but how much functionality they can produce. So if you were going to measure that in terms of development time, and you had a good broken up requirement stage with clearly separated use cases, you might want to know how many use cases they can deliver per month rather than how many lines of code. That would be a more effective, maybe a sort of closer effective measure of productivity. So you can think of working out how many source lines of code, object code instructions, and you can look at that. You can measure that. So the benefit of that is it's a clear objective measure. So you can go to the developer, and you can look at the source code control, and you could see how many lines of code were in each module and how many they produced each week, because you could easily measure that, or you could write a script to measure that. But there are things which are so-called function related measures, and there is one called function points which tries to estimate what the functionality of the software is. The difference between these two is that you can calculate or estimate function points from a requirement spec. You don't need to actually look at the code itself. So doing a size related measure is harder to do, because you can only do it accurately when some code's actually being developed. The function related measure you can do off the detailed design of the software, including all the UI screens. So when you're doing the measurement, there are a number of issues. So the first thing is just working out how big the code is. Then looking at working out how long the programmers have been actually working on that project. And then looking at the productivity. So productivity is going to be very different depending on the type of project you're working on. So something like an embedded system, real time system, the productivity is going to be considerably slower than a simpler information system. So lines of code were a measure. This was first proposed a long time ago when the code itself was typed onto cards, and there was one line per card. Typically, the code was written in assembler language, and each line of code did about the same amount of complexity. If you compare lines of code to actual statements in Java, the statement in Java can be a lot more complex and subtle, and you can have several statements shoved onto one line which do a lot more complexity. The other one is you need to worry about what programs are part of the system and what not, and the other one is that this assumes there's a sort of-- when you're trying to do-- estimate lines of code, is that the size of the documentation is going to give you a reflection of the amount of functionality in terms of lines of code, and that's not often the case. So if I say include an encryption algorithm like DES or AES, that's just what I'm going to do. Or AES, that's just one sentence. That might be hundreds and hundreds of lines of code to implement that, and then I'm out of pages and pages of stuff that will be actually relatively easy, because it's just some HTML page. So the amount and size of the documentation, it's not necessarily going to reflect the complexity involved in terms of lines of code. If you're working in a lower level language, generally the programmer is more productive in terms of lines of code. But that doesn't make any-- that's not very interesting to us, because at a lower level language, you need a lot more lines of code to implement the same thing as in a high level language. That's why we use high level languages. They're productive, aren't they? They allow us to very quickly write a program. It's a lot easier. So if you compare the two in terms of the amount of time required, you'll notice with the low level language, particularly in the last stage where you're doing the validation, there's a lot more time required in testing and validation. And the reason for that is if you're working in a high level language, when you compile the code, it throws out a lot of the errors that you've already generated. So it'll do type checking for you. When you run the code, it'll look for null pointer exceptions. It will give you loads of warnings about the code to say this might be an error, like you haven't used this variable. So you should probably delete it and make sure-- or use it appropriately. So when you use a high level language, the validation is a considerably shorter phase, because the language itself tends to produce higher quality code in the first place. Code that is low level languages, the code has high levels of coupling. So I talked about coupling and cohesion before. Coupling and cohesion lead to problems with validation and the longer time to finish the code. Function points in comparison to lines of code are based on how the code is in terms of user screens and access to database tables. So typically, function points can be done as soon as you have a detailed requirements analysis of the code. So that is what database tables need updating and what user screens they are. So all the interactions in terms of what the screens will be. So you can obviously get that off the requirements if you've done a mock up of the user interface. External interfaces, after you've done the design of the system, working out what database tables you need, and files, et cetera. So the idea of this is going to map the requirements of the system to how big the system will be. With each one of those points, they have a weighting factor depending on how complex it is. So if you have a particularly complex database table where you have to do some horrible inner join or something on a number of tables, something has to be optimized, you would have a higher weighting. Then you calculate, you do a multiplication depending on the complexity of it, and you add the numbers up, and you get a number at the end that's called the function points of the project. And you can then use that, feed that into the estimation of the time taken for the project itself. There is another measure called object points. Not the same as object classes, they're quite different. So again, this is like function points, it's a related measure. But it has things like screens and reports, a bit like the function points. But it also, if you can define extra modules that must be developed. So for example, I taught before about you needing an encryption module, you could include that in the module section. So the function point one assumes that you basically got screens and you're updating a database, and then you're just retrieving information on the database. The function point one is very information systems oriented. The object point one allows you to introduce factors that won't have been relevant in the function point one, because it's not that simple type of information system. So it's a bit more up to date. In terms of estimations of productivity for different systems, it very much depends on the type of system. So the slowest type of development are real time embedded systems. So that is doing things where there may not be an inherent operating system, or if there is an operating system, it's very, very small operating system. So there's not a lot of information in a small operating system, so it's not there to do all the complexity. You might have to interface the hardware, you might have to write device drivers. All this stuff is considered hard programming, and takes time and care. It involves things like-- oh, you have things like where the timing is very critical to talk to a piece of hardware, otherwise the data isn't available. So that productivity, that, because it's particularly difficult, lines of code per month can be as low as 40 lines. And if you know anything about coding by now, you'll notice 40 lines of code is not a lot of code. It's a very small amount of code. Very easy to get over that. If you're doing systems programming, so here you're doing program integrated with the operating system, but it's still relatively low level, a little bit more. And then commercial applications, when you're working in an environment where it's more of an information system, a lot of screen work, up to 800 lines of code per month. But again, these are rather archaic things nowadays, because the lines of code have changed as time changes. So productivity for high level languages now is probably higher than that, because you've got a lot better languages. Because these estimates were done a while ago. This typically relates more things like assembly language. In terms of object points, the range of productivity ranged between 4 and 50 object points. Well, that seems a lot, doesn't it? That means that that's an order of magnitude of range of productivity that's been estimated. And that depends very much on what you're developing and what the developer's capable of doing. So if you think about the difference in costing here, that's the difference of costing of by times by 10. So that's massive. So notice in object points, the range of productivity is a lot higher. There'll be a number of factors that are gonna affect productivity. So if you're doing an account system and your developers know how to do account system, it's gonna be a lot easier, effectively, for them to work in it. If they use a better development process, that can improve productivity. So using small classes that have higher cohesion and lower coupling will give you better productivity. If you have good reuse, so you're using object-oriented inheritance, you'll have better productivity. If you're doing a larger project, generally productivity gets reduced, it goes down. If you use good technology support, so you use good IDEs, that makes a lot of difference to productivities because you get a lot more support in terms of bug management. And then generally, a good working environment. So you know if you've got noise or distractions, that can affect the working environment, can affect your productivity. The problem with productivity and measuring things in terms of amount of code per unit time is that it doesn't necessarily take the quality of the code into account. Now what I'm talking about here is not the number of bugs because you presume they have to get rid of the bugs. What I'm talking about here is just the quality of the code after you actually have a look at it. So is the code well commented? Is the code portable? Is it flexible? Is it easy to change the code in a new project? It's relatively a lot easier to put code in, to type code in that isn't very flexible, it's not very well done, that just satisfies this question. So you can increase productivity by lowering the quality of the code. If you say, "Oh, don't bother commenting, "just type the code in, don't bother having using any, "don't write your classes well, "don't worry about doing a lot of design work." You can get the code out quickly, but it's really poor. So it's difficult to work out what the relationship between the two is, but generally it's a big mistake to focus simply on productivity. And very often for some projects, the project itself, a lot of the work involves refactoring or improving the code. So you might have a block of legacy code, you want to improve it, refactor it, you actually might find that you improve the code by cutting out lines or making the code shorter, or just improving the commenting. That way productivity will look as if it's going backwards, I'm actually removing lines of code. Well, actually removing lines of code is quite a good thing to do to a project, 'cause if you have less lines of code, you have less lines that you can have a bug on. So if I have 800 lines of code, if I can do that in 400 and it's well written, and it's elegant and it's nicely written, then it's easier to read the code, it's improving it. Once I've estimated the amount of code I have to do, I then have to try and estimate the amount of effort that's required to develop it. So typically, the earlier the estimate is done, then we don't have as much information about what we're going to be required in terms of the effort. So at the initial phase, when I first sent you that requirement for the alarm system, you just had a basic requirement. If I asked you how long that would take, well, you might say eight weeks or whatever, or 12 weeks, you might have a quick idea of how long it's gonna take. Then when you did the use case analysis, 'cause you have a lot more detailed information about the system, you'll come up with another estimate. Then once you did all the class diagrams and you looked at exactly how many classes are required, you'd have a more accurate view. So as you move through the project, you get a clearer view of how long the project's gonna take. So it's very important, these processes, like doing the requirements analysis and doing the design, they help you to do the estimation. They're quite useful. You might be working on operating systems which you're not familiar with or unfamiliar hardware. You might be working with people you haven't worked with before, or you might be asking other people outside your organization to do the development. Sometimes, there may be a degree of self-fulfillment of prophecy. So you might do an estimate defining the budget, and then the product's just adjusted to do that. So you might say it's gonna cost 100,000 pounds. You've got through 90,000 pounds worth of it. You start to wrap up the project because you know you haven't got any more money to go into the project itself. There is a number of approaches for doing your estimation. Namely, algorithmic cost modeling, expert judgment, estimation by analogy, Parkinson's Law and pricing to win. So algorithmic cost modeling. So what this involves is looking at many, many, many, many previous projects, not necessarily in your organization, in lots of organizations, and use them to produce a model that shows a relationship between the size of the code and how much effort's gonna require to develop it. Expert judgment. You get people who have done a lot of development before and ask them to do a prediction of how much the software's gonna cost. Typically, they will work in a process of discussion, in iteration, finding out more and more about the project until they develop some sort of consensus. There is a particular style of expert judgment which is called poker planning, which is commonly used in Scrum today. So it's a way of working on that. We do poker planning. I cover that in software engineering too, but go and have a look at it. It's an interesting and it's a useful way of working. You could use poker planning, for example, for your group software projects 'cause you work in small groups. It's ideally designed for that. But that's the type of expert judgment. So it's relatively cheap. You just work together as a group and it can be accurate if you have enough knowledge between you as a group of the experience of developing similar systems. It's certainly considered one of the most lightweight and straightforward examples. It's obviously not gonna be very accurate if you don't have people who are experts in developing that type of software. Next one is estimation by analogy. This you look at previous projects and see if your project is similar to those projects. And if it is, then assume that it's gonna take a similar amount of effort or a similar amount of effort plus some depending on the added complexity. So if you've got previous, lots of previous projects available and of a similar size, it will produce hopefully an accurate measure. But it's difficult and it's impossible if you haven't got a comparable project. So now we need to keep a database of past projects and we have to know quite a lot about them before we can produce an effective analogy. Next one is called Parkinson's Law. Parkinson's Law says that it will take, the project will take whatever costs or resources are available. An example of Parkinson's Law is you doing your work here in your group software project or your final project. The reason why it's an example of Parkinson's Law is you only have so many months to do it in and you're gonna use all those months up. Okay, so if we give you eight months to do it, that's the amount of time you have, that's all it's saying. The truth is is that some places like, some places like organizations like the Ministry of Defense that have a lot of money to go into projects, so projects that get overfunded with money, they go say, oh, we need 20 million to do this. What they're gonna do is they're gonna spend 20 million even if 20 million wasn't required in the first place. So this is typical for government projects where there's too much money thrown at a project, you'll find they're spending a lot of time doing a lot of things they didn't necessarily need to do to use up the resources available. So the law says that the work will expand to fill the time available, okay. And then the costing is determined by the available resources it may be the system's unfinished, it may be the system's finished way before time and then made over complex later on. So if you say a project's got to be delivered in 12 months and you've got five people, that's the amount of effort that goes into it. The next one is pricing a contract based on what the customer has to spend on the contract. So if the customers comes to you and says it costs 20,000 pounds, you put the cost up 20,000 pounds. The benefit of that is you may well win the contract but the disadvantage of this is that you may not get a project that the customer actually wants as software. But the reason being is that they as a customer don't necessarily know how much effort's required to go into the project. So it might be that you get to the end of the time and you've run out of money and then they don't get what they want to do because you haven't had the development time to put into it 'cause you've run out of money on the project. So they'll end up with something that's not right. Or it's possible that you just deliver something that is okay but then the customer's not very happy 'cause they thought they spent a lot of money on the project. So it's not necessarily, it's only gonna work in certain very restrictive environments. For all of these approaches in doing estimation, you can work from the top down or the bottom up. In general, top down is considered to be a more stable approach and it's closer to how you work in object-oriented development. So the top down, you start at the top level and look at all the subsystems, all the functionality. You break that up into subsystems and subsystems. They're very similar to top down testing. Starting at the user interface, break it down into little blocks and you add those all up. In bottom up, you're looking at all the different components that you've already got and then add those reaches up to give the final estimate. Bottom up testing is often, bottom up, sorry, estimation, is often related to code reuse. So you're looking at what code you've already got and then you say, how much cost will it be to adapt it to our new project? So generally, the methods themselves have strengths and weaknesses and it's a good idea to do at least a couple of different methods because then if you get very different results, it implies that you might have a problem with your estimation. So when you looked at the expert judgment, so in like poker planning, you can use that to produce one estimate and then you could do the work brace assessment, break it up into separate components to produce another one. For some projects, pricing to win's the only applicable method because you haven't got enough information about the project before you start off. The estimating itself is based on people's previous experience because then they know because they've done this work before. But certain methods will produce different estimates of development. So if you compare something like object-oriented rather than function-oriented development, object-oriented development gives you this, it's very useful if you've got stateful objects and you're looking for things like information systems, but you will be doing different development techniques. So for example, if you're doing algorithms for a router, algorithms for a communication gateway or something like that, it would probably be a good idea to use a function-oriented programming language such as Erlang or something like that. And that would be a different style of development. There are certain things you cannot do in function-oriented development require you to code in a different way. The difference between these and the two is this code is usually quicker to develop, but this code is a lot quicker to debug because it's a lot less buggy. So function-oriented development gives you a very stable code base. If you can use function-oriented development, it's worth learning about, it's worth learning to do for certain environments because it's very, very stable. There's going to be difference between a client-server system and a main central system. Client-server systems generally are more complex. If you're gonna use previous components to build your software, hopefully it'll be a lot quicker. Component-based software engineering is gonna be a lot quicker, it's gonna save you a lot of time. And then what case tools are you gonna use and what generators are the code? So these are things like Visual Studio, allow you to do a lot of development of the UI very, very quickly. It's obviously gonna cut down on your efforts. Pricing to win, okay, this is where you give a price based on what you know the budget is available, may seem a bit unethical on business life. The thing with pricing to win is it assumes if there's a price behind the project to start off with. Obviously if it's a closed tender, you're not gonna have a price that you're gonna be able to price to win to, okay? It is sometimes appropriate when you don't know enough information about the project itself. So you can say we can do the project for a certain cost. So typically with this, you have an outline proposal and then you say we're gonna do 20,000 pounds worth of development on this project and then you have to pay for more development on top. So then you produce a more detailed specification later on or you use the evolutionary approach as you develop the software and you have to charge per unit of development rather than come to an agreed cost beforehand. So it involves obviously a trusting relationship between you as a contractor and the customer. The final method is called algorithmic cost modeling. This was developed by a guy called Barry Bowen when he was working at the Chrysler Corporation on a number of projects. And he worked out that the relationship between the amount of effort required to go into a project was exponential based on the size. So you see this, it's this constant times the size to some power of B where B is greater than one. That means as the project gets bigger, the amount of development does not go up as a linear, it goes up as an exponential curve. That means a lot larger projects are less productive than smaller projects, it becomes more difficult. So this power shows you, this B power shows you how the larger projects are gonna be more difficult. And then you've got this M which depends on the type of project. So for things like embedded systems, real time systems, M is a lot bigger number than information systems. So the idea of this formula was you could put in loads of different factors about the project and get some reasonable estimates. There's a lot of work being done about this. Algorithmic cost modeling, sometimes it's called COCOMO. If you have a look it up, there's been a lot of tools that are being developed to work on it. So this, there's been a lot of development work done on this, a lot of research, but it's not as widely used for a lot of people than things like poker planning, which is an expert method. So this become a little bit outdated now, but there are still people using it. Generally, we only know the size of the software in terms of lines of code when it's actually finished. Okay, and the amount of final code that we get depends on the amount of reuse we have in other programming languages, of other components, what programming language we're gonna be using, and then is the system distributed, is it a client service system, et cetera. So as we go through the development, then the estimate becomes more accurate. So what you generally do is you keep doing the estimate as you move through the development phase. So you do one estimate at the beginning, week one, then you do the requirements analysis, then you do another estimate, then you do the detailed class diagram, then you do another estimate working through. Okay, so that's what you call a very quick introduction